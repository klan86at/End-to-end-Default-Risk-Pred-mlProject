{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5225afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70bce34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a26c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the current working directory to the project root\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ded22f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72de34a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_data_file: Path\n",
    "    local_data_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81089b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultMlProj.constants.constant import *\n",
    "from defaultMlProj.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601dfa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        config = self.config.data_ingestion\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            source_data_file=config.source_data_file,\n",
    "            local_data_file=config.local_data_file\n",
    "        )\n",
    "        return data_ingestion_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70f1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from defaultMlProj import logger\n",
    "from defaultMlProj.utils.common import get_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cfc6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIngestion:\n",
    "    def __init__ (self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def copy_data_file(self):\n",
    "\n",
    "        source = Path(self.config.source_data_file)\n",
    "        destination = Path(self.config.local_data_file)\n",
    "\n",
    "        try:\n",
    "            logger.info(f\"Starting data ingestion:copying{source} to {destination}\")\n",
    "\n",
    "            destination.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            if not source.exists():\n",
    "                raise Exception(f\"Source file {source.absolute()} does not exist\")\n",
    "\n",
    "            if destination.exists():\n",
    "                logger.info(f\"File destination {destination} already exists. Skipping copy.\")\n",
    "            else:\n",
    "                shutil.copy(source, destination)\n",
    "                logger.info(f\"File copied successfully: {source} to {destination}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error occurred while copying data file: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f96d2da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: d:\\End-to-end-Default-Risk-Pred-mlProject\n",
      "Expected source path: d:\\End-to-end-Default-Risk-Pred-mlProject\\notebook\\data\\default.csv\n",
      "Does file exist? True\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define the expected path\n",
    "source_path = Path(\"notebook/data/default.csv\")\n",
    "\n",
    "print(\"Current working directory:\", Path(\".\").absolute())\n",
    "print(\"Expected source path:\", source_path.absolute())\n",
    "print(\"Does file exist?\", source_path.exists())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67bbb478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-22 23:44:21,641: INFO: common: YAML file config\\config.yaml loaded successfully.]\n",
      "[2025-07-22 23:44:21,645: INFO: common: YAML file params.yaml loaded successfully.]\n",
      "[2025-07-22 23:44:21,647: INFO: common: Created directory: artifacts]\n",
      "[2025-07-22 23:44:21,648: INFO: common: Created directory: artifacts/data_ingestion]\n",
      "[2025-07-22 23:44:21,649: INFO: 653153596: Starting data ingestion:copyingnotebook\\data\\default.csv to artifacts\\data_ingestion\\default.csv]\n",
      "[2025-07-22 23:44:21,652: INFO: 653153596: File copied successfully: notebook\\data\\default.csv to artifacts\\data_ingestion\\default.csv]\n"
     ]
    }
   ],
   "source": [
    "# Updating the pipeline item on the workflow list\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_ingestion_config = config.get_data_ingestion_config()\n",
    "    data_ingestion = DataIngestion(config=data_ingestion_config)\n",
    "    data_ingestion.copy_data_file()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15113f",
   "metadata": {},
   "source": [
    "##### Stage two Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "223bd55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0bacc249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29517b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e19d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05920099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab9f0de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_score</th>\n",
       "      <th>income</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>employment_years</th>\n",
       "      <th>savings_balance</th>\n",
       "      <th>age</th>\n",
       "      <th>default_risk_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>810</td>\n",
       "      <td>107410</td>\n",
       "      <td>11924</td>\n",
       "      <td>48</td>\n",
       "      <td>7.97</td>\n",
       "      <td>43.29</td>\n",
       "      <td>32</td>\n",
       "      <td>27181</td>\n",
       "      <td>58</td>\n",
       "      <td>7634.543366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>418</td>\n",
       "      <td>37482</td>\n",
       "      <td>19291</td>\n",
       "      <td>24</td>\n",
       "      <td>6.94</td>\n",
       "      <td>11.01</td>\n",
       "      <td>33</td>\n",
       "      <td>15089</td>\n",
       "      <td>43</td>\n",
       "      <td>6249.833059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>724</td>\n",
       "      <td>85641</td>\n",
       "      <td>39501</td>\n",
       "      <td>36</td>\n",
       "      <td>8.59</td>\n",
       "      <td>37.11</td>\n",
       "      <td>0</td>\n",
       "      <td>97459</td>\n",
       "      <td>33</td>\n",
       "      <td>2148.117990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>444</td>\n",
       "      <td>73331</td>\n",
       "      <td>25714</td>\n",
       "      <td>36</td>\n",
       "      <td>13.09</td>\n",
       "      <td>33.39</td>\n",
       "      <td>18</td>\n",
       "      <td>2413</td>\n",
       "      <td>48</td>\n",
       "      <td>4979.385344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>440</td>\n",
       "      <td>46723</td>\n",
       "      <td>35651</td>\n",
       "      <td>36</td>\n",
       "      <td>8.30</td>\n",
       "      <td>46.21</td>\n",
       "      <td>6</td>\n",
       "      <td>9716</td>\n",
       "      <td>42</td>\n",
       "      <td>2993.851950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   credit_score  income  loan_amount  loan_term  interest_rate  \\\n",
       "0           810  107410        11924         48           7.97   \n",
       "1           418   37482        19291         24           6.94   \n",
       "2           724   85641        39501         36           8.59   \n",
       "3           444   73331        25714         36          13.09   \n",
       "4           440   46723        35651         36           8.30   \n",
       "\n",
       "   debt_to_income_ratio  employment_years  savings_balance  age  \\\n",
       "0                 43.29                32            27181   58   \n",
       "1                 11.01                33            15089   43   \n",
       "2                 37.11                 0            97459   33   \n",
       "3                 33.39                18             2413   48   \n",
       "4                 46.21                 6             9716   42   \n",
       "\n",
       "   default_risk_score  \n",
       "0         7634.543366  \n",
       "1         6249.833059  \n",
       "2         2148.117990  \n",
       "3         4979.385344  \n",
       "4         2993.851950  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r\"artifacts/data_ingestion/default.csv\", sep=\"\\t\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e8ddc94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48d27eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   credit_score          800 non-null    int64  \n",
      " 1   income                800 non-null    int64  \n",
      " 2   loan_amount           800 non-null    int64  \n",
      " 3   loan_term             800 non-null    int64  \n",
      " 4   interest_rate         800 non-null    float64\n",
      " 5   debt_to_income_ratio  800 non-null    float64\n",
      " 6   employment_years      800 non-null    int64  \n",
      " 7   savings_balance       800 non-null    int64  \n",
      " 8   age                   800 non-null    int64  \n",
      " 9   default_risk_score    800 non-null    float64\n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 62.6 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad5bd69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    all_schema: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2596ae7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultMlProj.constants.constant import *\n",
    "from defaultMlProj.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2016e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.columns\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            STATUS_FILE=config.STATUS_FILE,\n",
    "            \n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db82293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from defaultMlProj import logger\n",
    "from defaultMlProj.entity.config_entity import DataValidationConfig\n",
    "import pandas as pd\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__ (self, config: DataValidationConfig):\n",
    "        self.config =config\n",
    "\n",
    "    def validate_all_columns(self) -> bool:\n",
    "        try:\n",
    "            logger.info(\"Starting data validation: validating all columns\")\n",
    "            validation_status = None\n",
    "\n",
    "            df = pd.read_csv(self.config.root_dir)\n",
    "            all_cols = list(df.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            for col in all_cols:\n",
    "                if col in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\\n\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\\n\")\n",
    "            logger.info(f\"Data validation completed with status: {validation_status}\")\n",
    "\n",
    "            return validation_status\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error occurred during data validation: {e}\")\n",
    "            raise e\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c326e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline creation\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValidation(config=data_validation_config)\n",
    "    data_validation.validate_all_columns()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8966d9e",
   "metadata": {},
   "source": [
    "#### Note: Validation stage skipped in my defaultMlProj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8179e0b",
   "metadata": {},
   "source": [
    "##### Workflows\n",
    "1. Update config.yaml\n",
    "2. Update schema.yaml\n",
    "3. Update params.yaml\n",
    "4. Update entity\n",
    "5. Update the configuration manager in src config\n",
    "6. Update the components\n",
    "7. Update the pipeline\n",
    "8. Update the main.py\n",
    "9. Update the app.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eadb700",
   "metadata": {},
   "source": [
    "#### Model transformation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d36cc87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformatonConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f7a1d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultMlProj.constants.constant import *\n",
    "from defaultMlProj.utils.common import read_yaml, create_directories\n",
    "\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformatonConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "        \n",
    "        data_transformation_config = DataTransformatonConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57e01b4",
   "metadata": {},
   "source": [
    "#### Model Transformation stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a383f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "135f2d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4fe0e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d458c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "429fdef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataTransformationConfig:\n",
    "    root_dir: Path\n",
    "    data_path: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567ff684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultMlProj.constants.constant import *\n",
    "from defaultMlProj.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44961782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_transformation_config(self) -> DataTransformationConfig:\n",
    "        config = self.config.data_transformation\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_transformation_config = DataTransformationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            data_path=config.data_path\n",
    "        )\n",
    "\n",
    "        return data_transformation_config\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e957f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# components/data_transformation.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from defaultMlProj import logger\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "    def __init__(self, config: DataTransformationConfig):\n",
    "        self.config = config\n",
    "        self.target_column = \"default_risk_score\"  # actual target column name\n",
    "\n",
    "\n",
    "    def train_test_split(self):\n",
    "        df = pd.read_csv(self.config.data_path, sep='\\t')\n",
    "\n",
    "        try:\n",
    "            logger.info(\"Starting data transformation: train-test split\")\n",
    "            logger.info(f\"Full dataset shape: {df.shape}\")\n",
    "\n",
    "            # Validate target column exists\n",
    "            if self.target_column not in df.columns:\n",
    "                raise ValueError(f\"Target column '{self.target_column}' not found in data. Columns: {list(df.columns)}\")\n",
    "\n",
    "            # Separate features and target\n",
    "            X = df.drop(columns=[self.target_column])\n",
    "            y = df[self.target_column]\n",
    "\n",
    "            logger.info(f\"Feature matrix X shape: {X.shape}\")  # Should be (800, 9)\n",
    "            logger.info(f\"Target vector y shape: {y.shape}\")   # Should be (800,)\n",
    "\n",
    "            # Perform train-test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y,\n",
    "                test_size=0.2,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            logger.info(f\"Train features shape: {X_train.shape}, Train target shape: {y_train.shape}\")\n",
    "            logger.info(f\"Test features shape: {X_test.shape}, Test target shape: {y_test.shape}\")\n",
    "\n",
    "            # Recombine for saving (optional: keeps target in dataset)\n",
    "            train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "            train_df[self.target_column] = y_train.values\n",
    "\n",
    "            test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "            test_df[self.target_column] = y_test.values\n",
    "\n",
    "            # Save to CSV\n",
    "            train_csv_path = os.path.join(self.config.root_dir, \"train.csv\")\n",
    "            test_csv_path = os.path.join(self.config.root_dir, \"test.csv\")\n",
    "\n",
    "            train_df.to_csv(train_csv_path, index=False)\n",
    "            test_df.to_csv(test_csv_path, index=False)\n",
    "\n",
    "            logger.info(f\"Train dataset saved to {train_csv_path}\")\n",
    "            logger.info(f\"Test dataset saved to {test_csv_path}\")\n",
    "\n",
    "            return train_df, test_df\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error occurred during train-test split: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0842fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-23 23:50:04,589: INFO: common: YAML file config\\config.yaml loaded successfully.]\n",
      "[2025-07-23 23:50:04,597: INFO: common: YAML file params.yaml loaded successfully.]\n",
      "[2025-07-23 23:50:04,604: INFO: common: Created directory: artifacts]\n",
      "[2025-07-23 23:50:04,608: INFO: common: Created directory: artifacts/data_transformation]\n",
      "[2025-07-23 23:50:04,623: INFO: 1805267760: Starting data transformation: train-test split]\n",
      "[2025-07-23 23:50:04,629: INFO: 1805267760: Full dataset shape: (800, 10)]\n",
      "[2025-07-23 23:50:04,654: INFO: 1805267760: Feature matrix X shape: (800, 9)]\n",
      "[2025-07-23 23:50:04,654: INFO: 1805267760: Target vector y shape: (800,)]\n",
      "[2025-07-23 23:50:04,671: INFO: 1805267760: Train features shape: (640, 9), Train target shape: (640,)]\n",
      "[2025-07-23 23:50:04,674: INFO: 1805267760: Test features shape: (160, 9), Test target shape: (160,)]\n",
      "[2025-07-23 23:50:04,712: INFO: 1805267760: Train dataset saved to artifacts/data_transformation\\train.csv]\n",
      "[2025-07-23 23:50:04,717: INFO: 1805267760: Test dataset saved to artifacts/data_transformation\\test.csv]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline creation\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_transformation_config = config.get_data_transformation_config()\n",
    "    data_transformation = DataTransformation(config=data_transformation_config)\n",
    "    data_transformation.train_test_split()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6898fe5f",
   "metadata": {},
   "source": [
    "#### Model Trainer Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1f547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d883c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "964373f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d27999a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc5de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59f77211",
   "metadata": {},
   "outputs": [],
   "source": [
    "from defaultMlProj.constants.constant import *\n",
    "from defaultMlProj.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5e13c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "    ):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_model_trainer_config(self) -> ModelTrainerConfig:\n",
    "        config = self.config.model_trainer\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        model_trainer_config = ModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "        )\n",
    "\n",
    "        return model_trainer_config\n",
    "    \n",
    "    def get_params(self):\n",
    "        \"\"\"\n",
    "        Returns the parameters loaded from params.yaml\n",
    "        \"\"\"\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a64798",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import xgboost\n",
    "from defaultMlProj import logger\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import StackingRegressor    \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ab46c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self, config: ModelTrainerConfig, params):\n",
    "        self.config = config\n",
    "        self.params = params\n",
    "        self.target_column = params.target_column\n",
    "\n",
    "    def create_model(self):\n",
    "        # from sklearn.pipeline import Pipeline\n",
    "        # from sklearn.preprocessing import StandardScaler\n",
    "        # from sklearn.linear_model import LinearRegression\n",
    "        # from sklearn.neighbors import KNeighborsRegressor\n",
    "        # from sklearn.tree import DecisionTreeRegressor\n",
    "        # from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "        try:\n",
    "            logger.info(\"Started creating models\")\n",
    "            # Extract params\n",
    "            p = self.params.model_params\n",
    "\n",
    "            models = {}\n",
    "\n",
    "            # Linear Regression\n",
    "            models['LinearRegression'] = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', LinearRegression(\n",
    "                    fit_intercept=p.linear_regression.fit_intercept\n",
    "                ))\n",
    "            ])\n",
    "\n",
    "            # KNN\n",
    "            models['KNN'] = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('regressor', KNeighborsRegressor(\n",
    "                    n_neighbors=p.knn.n_neighbors,\n",
    "                    weights=p.knn.weights,\n",
    "                    algorithm=p.knn.algorithm\n",
    "                ))\n",
    "            ])\n",
    "\n",
    "            # Decision Tree\n",
    "            models['DecisionTree'] = DecisionTreeRegressor(\n",
    "                criterion=p.decision_tree.criterion,\n",
    "                max_depth=p.decision_tree.max_depth,\n",
    "                min_samples_split=p.decision_tree.min_samples_split,\n",
    "                min_samples_leaf=p.decision_tree.min_samples_leaf,\n",
    "                random_state=p.decision_tree.random_state\n",
    "            )\n",
    "            \n",
    "            # Random Forest\n",
    "            models['RandomForest'] = RandomForestRegressor(\n",
    "                n_estimators=p.random_forest.n_estimators,\n",
    "                criterion=p.random_forest.criterion,\n",
    "                max_depth=p.random_forest.max_depth,\n",
    "                min_samples_split=p.random_forest.min_samples_split,\n",
    "                min_samples_leaf=p.random_forest.min_samples_leaf,\n",
    "                random_state=p.random_forest.random_state\n",
    "            )\n",
    "\n",
    "            # Stacking Regressor\n",
    "            base_estimators = list(models.items())\n",
    "\n",
    "            final_estimator = LinearRegression(\n",
    "                fit_intercept=p.linear_regression.fit_intercept\n",
    "            )\n",
    "\n",
    "            stacking = StackingRegressor(\n",
    "                estimators=base_estimators,\n",
    "                final_estimator=final_estimator,\n",
    "                cv=p.stacking_regressor.cv,\n",
    "                n_jobs=p.stacking_regressor.n_jobs\n",
    "            )\n",
    "\n",
    "            models['Stacking Regressor'] = stacking\n",
    "            logger.info(f\"Models created: {list(models.keys())}\")\n",
    "            return models\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error occurred while creating models: {e}\")\n",
    "            raise e\n",
    "        \n",
    "    def train_and_evaluate(self):\n",
    "        logger.info(\"Starting model training with external parameters\")\n",
    "        try:\n",
    "            # Load data\n",
    "            train_df = pd.read_csv(self.config.train_data_path, sep=',')\n",
    "            test_df = pd.read_csv(self.config.test_data_path, sep=',')\n",
    "            \n",
    "            logger.info(f\"Train data shape: {train_df.shape}, Test data shape: {test_df.shape}\")\n",
    "\n",
    "            X_train = train_df.drop(columns=[self.target_column])\n",
    "            y_train = train_df[self.target_column]\n",
    "            X_test = test_df.drop(columns=[self.target_column])\n",
    "            y_test = test_df[self.target_column]\n",
    "\n",
    "            logger.info(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "            logger.info(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "            # Create models using params\n",
    "            models = self.create_model()\n",
    "\n",
    "            # Get CV settings from params\n",
    "            cv_params = self.params.cv_settings\n",
    "            cv = KFold(\n",
    "                n_splits=cv_params.n_splits,\n",
    "                shuffle=cv_params.shuffle,\n",
    "                random_state=cv_params.random_state\n",
    "            )\n",
    "            results = {}\n",
    "\n",
    "            for name, model in models.items():\n",
    "                try:\n",
    "                    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
    "                    results[name] = scores\n",
    "                    logger.info(f\"{name} R2 = {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "                except Exception as e:\n",
    "                    logger.exception(f\"Failed to evaluate {name}: {e}\")\n",
    "                    raise e\n",
    "                \n",
    "            # The best model\n",
    "            best_name = max(results, key=lambda k: results[k].mean())\n",
    "            best_model = models[best_name].fit(X_train, y_train)\n",
    "\n",
    "            # Final evaluation\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            test_r2 = r2_score(y_test, y_pred)\n",
    "            test_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "            logger.info(f\"Best model: {best_name} | Test R2 : {test_r2:.4f}, RMSE : {test_rmse:.4f}\")\n",
    "\n",
    "            # Save model\n",
    "            Path(self.config.model_name).parent.mkdir(parents=True, exist_ok=True)\n",
    "            joblib.dump(best_model, self.config.model_name)\n",
    "            logger.info(f\"Model saved to {self.config.model_name}\")\n",
    "\n",
    "            return best_model, test_r2, test_rmse\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error occurred during model training and evaluation: {e}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a23e920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-24 12:53:06,629: INFO: common: YAML file config\\config.yaml loaded successfully.]\n",
      "[2025-07-24 12:53:06,651: INFO: common: YAML file params.yaml loaded successfully.]\n",
      "[2025-07-24 12:53:06,657: INFO: common: Created directory: artifacts]\n",
      "[2025-07-24 12:53:06,663: INFO: common: Created directory: artifacts/model_trainer]\n",
      "[2025-07-24 12:53:06,666: INFO: 1173455576: Starting model training with external parameters]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-24 12:53:06,692: INFO: 1173455576: Train data shape: (640, 10), Test data shape: (160, 10)]\n",
      "[2025-07-24 12:53:06,700: INFO: 1173455576: X_train shape: (640, 9), y_train shape: (640,)]\n",
      "[2025-07-24 12:53:06,705: INFO: 1173455576: X_test shape: (160, 9), y_test shape: (160,)]\n",
      "[2025-07-24 12:53:06,712: INFO: 1173455576: Started creating models]\n",
      "[2025-07-24 12:53:06,720: INFO: 1173455576: Models created: ['LinearRegression', 'KNN', 'DecisionTree', 'RandomForest', 'Stacking Regressor']]\n",
      "[2025-07-24 12:53:06,829: INFO: 1173455576: LinearRegression R2 = 1.0000 (+/- 0.0000)]\n",
      "[2025-07-24 12:53:06,942: INFO: 1173455576: KNN R2 = 0.8425 (+/- 0.0246)]\n",
      "[2025-07-24 12:53:07,101: INFO: 1173455576: DecisionTree R2 = 0.9993 (+/- 0.0003)]\n",
      "[2025-07-24 12:53:10,613: INFO: 1173455576: RandomForest R2 = 0.9995 (+/- 0.0001)]\n",
      "[2025-07-24 12:53:31,131: INFO: 1173455576: Stacking Regressor R2 = 1.0000 (+/- 0.0000)]\n",
      "[2025-07-24 12:53:31,146: INFO: 1173455576: Best model: LinearRegression | Test R2 : 1.0000, RMSE : 9.9754]\n",
      "[2025-07-24 12:53:31,146: INFO: 1173455576: Model saved to artifacts/model_trainer/model.joblib]\n"
     ]
    }
   ],
   "source": [
    "# Pipeline creation\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    model_trainer_config = config.get_model_trainer_config()\n",
    "    params = config.get_params()\n",
    "    model_trainer = ModelTrainer(config=model_trainer_config, params=params)\n",
    "    model_trainer.train_and_evaluate()\n",
    "except Exception as e:\n",
    "    logger.info(f\"Error in model training pipeline: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2bc8e039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in train_df: ['credit_score,income,loan_amount,loan_term,interest_rate,debt_to_income_ratio,employment_years,savings_balance,age,default_risk_score']\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(model_trainer_config.train_data_path, sep='\\t')\n",
    "print(\"Columns in train_df:\", train_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610a304",
   "metadata": {},
   "source": [
    "#### Model Evaluation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c486280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3191a3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject\\\\notebook'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b206650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af91934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\End-to-end-Default-Risk-Pred-mlProject'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3296da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
